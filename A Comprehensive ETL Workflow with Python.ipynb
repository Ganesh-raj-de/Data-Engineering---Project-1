{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Gather Data Files\n",
    "Open a terminal and download the dataset:\n",
    "Use the wget command to download the dataset containing multiple file formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries and Set Paths\n",
    "You need to import necessary libraries like:\n",
    "glob to handle file formats.\n",
    "pandas to read CSV and JSON files.\n",
    "xml.etree.ElementTree to parse XML data.\n",
    "datetime to track the progress of each phase through logging.\n",
    "Install the pandas library if it's not already installed.\n",
    "Set up paths for:\n",
    "log_file.txt to record the logs.\n",
    "transformed_data.csv to save the final output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\ganeshraj.subramani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\ganeshraj.subramani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ganeshraj.subramani\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ganeshraj.subramani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ganeshraj.subramani\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ganeshraj.subramani\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths set up successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "log_file_path = \"log_file.txt\"\n",
    "output_csv_path = \"transformed_data.csv\"\n",
    "\n",
    "# Create an empty log file if it doesnâ€™t exist\n",
    "if not os.path.exists(log_file_path):\n",
    "    with open(log_file_path, \"w\") as log_file:\n",
    "        log_file.write(\"Log File Created\\n\")\n",
    "\n",
    "print(\"Paths set up successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = \"log_file.txt\"\n",
    "\n",
    "def log_message(message):\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    log_entry = f\"{timestamp} - {message}\\n\"\n",
    "    with open(log_file, \"a\") as log:\n",
    "        log.write(log_entry)\n",
    "    print(log_entry.strip())  # Print log to console\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv = \"transformed_data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions for each step of  ETL as follows:\n",
    "Extract Data:\n",
    "Three different functions to extract data from CSV, JSON, and XML files respectively.\n",
    "A master function will call the relevant function based on the file type and combine the extracted data into a single DataFrame.\n",
    "Transform Data:\n",
    "The transformation process involves converting:\n",
    "Heights from inches to meters.\n",
    "Weights from pounds to kilograms.\n",
    "This step ensures the data is in the desired format for further analysis or storage.\n",
    "Load Data:\n",
    "The transformed data is saved to a CSV file, which can later be loaded into a relational database or used for further processing.\n",
    "Logging:\n",
    "Throughout the ETL process, each phase (Extraction, Transformation, Loading) is logged with a timestamp to ensure traceability and monitoring.\n",
    "Logs are saved in a text file for auditing or troubleshooting purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\ganeshraj.subramani\\Downloads\\source\\file.csv\"\n",
    "\n",
    "def extract_csv(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        log_message(f\"Successfully extracted data from {file_path}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error extracting CSV {file_path}: {str(e)}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Extract from JSON\n",
    "def extract_json(file_path):\n",
    "    try:\n",
    "        df = pd.read_json(file_path)\n",
    "        log_message(f\"Successfully extracted data from {file_path}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error extracting JSON {file_path}: {str(e)}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Extract from XML\n",
    "def extract_xml(file_path):\n",
    "    try:\n",
    "        tree = ET.parse(file_path)\n",
    "        root = tree.getroot()\n",
    "        data = []\n",
    "        for record in root.findall(\"record\"):\n",
    "            row = {child.tag: child.text for child in record}\n",
    "            data.append(row)\n",
    "        df = pd.DataFrame(data)\n",
    "        log_message(f\"Successfully extracted data from {file_path}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error extracting XML {file_path}: {str(e)}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(source_folder):\n",
    "    all_data = pd.DataFrame()\n",
    "    for file in glob.glob(f\"{source_folder}/*\"):\n",
    "        if file.endswith(\".csv\"):\n",
    "            df = extract_csv(file)\n",
    "        elif file.endswith(\".json\"):\n",
    "            df = extract_json(file)\n",
    "        elif file.endswith(\".xml\"):\n",
    "            df = extract_xml(file)\n",
    "        else:\n",
    "            log_message(f\"Skipping unknown file format: {file}\")\n",
    "            continue\n",
    "\n",
    "        all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "\n",
    "    log_message(\"Data extraction completed.\")\n",
    "    return all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df):\n",
    "    try:\n",
    "        df[\"height\"] = df[\"height\"].astype(float) * 0.0254  # Inches to meters\n",
    "        df[\"weight\"] = df[\"weight\"].astype(float) * 0.453592  # Pounds to kilograms\n",
    "        log_message(\"Data transformation completed.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error during transformation: {str(e)}\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(df, output_path):\n",
    "    try:\n",
    "        df.to_csv(output_path, index=False)\n",
    "        log_message(f\"Transformed data saved to {output_path}\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"Error saving transformed data: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction Phase:\n",
    "The project extracts data from all CSV, JSON, and XML files located in the project directory.\n",
    "Each file type is processed, and the results are combined into one DataFrame.\n",
    "Transformation Phase:\n",
    "The extracted data undergoes transformation to convert the measurements to standard units (e.g., height to meters, weight to kilograms).\n",
    "Loading Phase:\n",
    "The transformed data is written into a CSV file, which can be imported into a database for further use.\n",
    "Logging:\n",
    "The start and end of each phase (Extraction, Transformation, Loading) are logged to track progress and ensure everything runs smoothly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_etl(source_folder):\n",
    "    log_message(\"ETL process started.\")\n",
    "\n",
    "    # Step 1: Extract\n",
    "    extracted_data = extract_data(source_folder)\n",
    "\n",
    "    # Step 2: Transform\n",
    "    transformed_data = transform_data(extracted_data)\n",
    "\n",
    "    # Step 3: Load\n",
    "    load_data(transformed_data, output_csv)\n",
    "\n",
    "    log_message(\"ETL process completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-08 21:00:55 - ETL process started.\n",
      "2025-02-08 21:00:55 - Data extraction completed.\n",
      "2025-02-08 21:00:55 - Error during transformation: 'height'\n",
      "2025-02-08 21:00:55 - Transformed data saved to transformed_data.csv\n",
      "2025-02-08 21:00:55 - ETL process completed.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    source_folder = \"unzipped_folder\"  # Change this if your files are in a different directory\n",
    "    run_etl(source_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
